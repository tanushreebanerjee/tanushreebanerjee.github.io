---
highlight: true
layout: post
title: "Inverse Neural Rendering for Explainable Multi-Object Tracking"
date:  2024-03-29
image: /tracking.gif
categories: research
slides: 
paper: pdfs/tracking_slides.pdf
supplementary: https://light.princeton.edu/wp-content/uploads/2024/04/ost_2024_neural_inverse_rendering_object_tracking_supplementary.pdf
video: 
author: "Tanushree Banerjee"
authors: <a href="https://scholar.google.com/citations?user=mUbWwU4AAAAJ&hl=en">Julian Ost*</a>, <u><strong>Tanushree Banerjee*</strong></u>, <a href="http://mariobijelic.de/wordpress/#/home">Mario Bijelic</a>, <a href="https://www.cs.princeton.edu/~fheide/">Felix Heide</a>
venue: ArXiv Preprint
arxiv: https://arxiv.org/abs/2404.12359
code: 
website: https://light.princeton.edu/publication/inverse-rendering-tracking/
---
We propose to recast 3D multi-object tracking from RGB cameras as an <em>Inverse Rendering</em> (IR) problem by optimizing via a differentiable rendering pipeline over the latent space of pre-trained 3D object representations and retrieving the latents that best represent object instances in a given input image. Our method is not only an alternate take on tracking; it enables examining the generated objects, reasoning about failure situations, and resolving ambiguous cases.
