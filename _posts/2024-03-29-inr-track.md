---
highlight: true
layout: post
title:  "Inverse Neural Rendering for Explainable Multi-Object Tracking"
date:  2024-03-29
image: /tracking.gif
categories: research
slides: pdfs/tracking_slides.pdf
paper: https://arxiv.org/pdf/2404.12359.pdf
supplementary: pdfs/tracking_supplementary.pdf
video: https://drive.google.com/file/d/1ef7OghH1fbhpptMZ_tXU4SBPVVoJWFO1/view?usp=sharing
author: "Tanushree Banerjee"
authors: <a href="https://scholar.google.com/citations?user=mUbWwU4AAAAJ&hl=en">Julian Ost*</a>, <strong>Tanushree Banerjee*</strong>, <a href="http://mariobijelic.de/wordpress/#/home">Mario Bijelic</a>, <a href="https://www.cs.princeton.edu/~fheide/">Felix Heide</a>
venue: ArXiv
arxiv: https://arxiv.org/abs/2404.12359
code: 
website: https://light.princeton.edu/publication/inverse-rendering-tracking/
---
We propose to recast 3D multi-object tracking from RGB cameras as an <em>Inverse Rendering</em> (IR) problem by optimizing via a differentiable rendering pipeline over the latent space of pre-trained 3D object representations and retrieving the latents that best represent object instances in a given input image. Our method is not only an alternate take on tracking; it enables examining the generated objects, reasoning about failure situations, and resolving ambiguous cases.
