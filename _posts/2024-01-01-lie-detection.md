---
layout: post
title:  "LLMs are Superior Feedback Providers: Bootstrapping Reasoning for Lie Detection with Self-Generated Feedback"
date: 2024-01-01
image: /diplomacy.png
categories: independent
course:
author: "Tanushree Banerjee"
authors: <strong>Tanushree Banerjee</strong>, <a href="https://richardzhu123.github.io/">Richard Zhu</a>, <a href="https://runzhe-yang.science/">Runzhe Yang</a>, <a href="https://denis.ai/">Denis Peskov</a>, <a href="https://bstewart.scholar.princeton.edu/">Brandon Stewart</a>, <a href="https://www.cs.princeton.edu/~karthikn/">Karthik Narasimhan</a>
paper: pdfs/diplomacy_main.pdf
slides: pdfs/diplomacy_slides.pdf
venue: 
arxiv: 
code: 
website: 
---

We investigated a bootstrapping framework that leverages self-generated feedback for detecting deception in Diplomacy games by collecting a novel dataset of human feedback on initial predictions and comparing the modification stage performance when using human feedback rather than LLM-generated feedback. Our LLM-generated feedback-based approach achieved superior performance, with a 39% improvement over the zero-shot baseline in lying-F1 without any training required.
