---
highlight: true
layout: post
title: "Towards generalizable and interpretable three-dimensional tracking with inverse neural rendering"
date:  2028-08-04
image: /tracking.gif
categories: research
slides: pdfs/tracking_slides.pdf
paper: https://www.nature.com/articles/s42256-025-01083-x.pdf
supplementary: https://static-content.springer.com/esm/art%3A10.1038%2Fs42256-025-01083-x/MediaObjects/42256_2025_1083_MOESM1_ESM.pdf
video: https://static-content.springer.com/esm/art%3A10.1038%2Fs42256-025-01083-x/MediaObjects/42256_2025_1083_MOESM3_ESM.mp4
tags: [3D multi-object tracking, explainability, inverse rendering]
author: "Tanushree Banerjee"
authors: <a href="https://scholar.google.com/citations?user=mUbWwU4AAAAJ&hl=en">Julian Ost*</a>, <u><strong>Tanushree Banerjee*</strong></u>, <a href="http://mariobijelic.de/wordpress/#/home">Mario Bijelic</a>, <a href="https://www.cs.princeton.edu/~fheide/">Felix Heide</a><br><strong>* denotes equal contribution</strong>
venue: Nature Machine Intelligence
arxiv:
code: https://github.com/princeton-computational-imaging/INRTracker
website: https://light.princeton.edu/publication/inverse-rendering-tracking/
---
Extending our previous <a href="https://arxiv.org/abs/2404.12359">arXiv preprint</a> recasting 3D multi-object tracking from RGB cameras as an <em>Inverse Rendering</em> (IR) problem to object classes other than vehicles and using several different generator models to showcase the generalization ability of our method.
