---
layout: post
title:  "What Makes In-Context Learning Work On Generative QA Tasks?"
date: 2022-12-01
image: /cos597g.png
categories: other
course: Understanding Large Language Models Course Project, Fall 2022 (Graduate Course)
author: "Tanushree Banerjee"
authors: <u><strong>Tanushree Banerjee*</strong></u>, <a href="https://parksimon0808.github.io/">Simon Park*</a>, <a href="https://www.linkedin.com/in/beiqi-zou-973a54157/">Beiqi Zou*</a>, <a href="https://www.cs.princeton.edu/~danqic/">Danqi Chen</a>
paper: pdfs/cos597g_final.pdf
slides:
venue: 
arxiv: 
code: https://github.com/tanushreebanerjee/COS597G_final_project
website: 
---

We empirically analyze what aspects of the in-context demonstrations contribute to improvements in downstream task performance, extending the work of Min et al., 2022 to multiple choice and classification tasks.
