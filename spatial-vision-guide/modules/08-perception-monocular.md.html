<!DOCTYPE html>
<meta charset="utf-8" emacsmode="-*- markdown -*-">
<link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/journal.css?">
<style>
/* Burgundy color theme override */
.md h1, .md h2, .md h3, .md h4, .md h5, .md h6 { color: #8B1538; }
.md a { color: #8B1538; }
.md a:hover { color: #A0446C; }
</style>

<!-- Markdeep: https://casual-effects.com/markdeep/ -->

# Monocular 3D Detection

**Module 8.3** | [‚Üê Back to Index](../index.html) | [Next: Occupancy & Scene Completion ‚Üí](08-perception-occupancy.md.html)

---

## Overview

Monocular 3D detection: Detect and localize 3D objects from single camera images. Challenging due to depth ambiguity, requires strong geometric priors or learned depth understanding.

---

## Essential Papers

### üî• Monocular 3D Object Detection (2019-2023)

**Key approaches**:
- Direct 3D regression from 2D features
- 2D detection + depth estimation
- Geometry-based methods using constraints

**Methods**:
- **Mono3D**: Multi-task learning (2D detection, depth, 3D box)
- **M3D-RPN**: 3D region proposal network
- **MonoPair**: Pairwise constraints for consistency
- **MonoDETR**: DETR-style end-to-end detection

**Challenges**: Depth ambiguity, scale ambiguity, occlusion.

---

### üöÄ Depth Anything 3 (2024)

**Key innovation**: Strong depth understanding for 3D detection.

**Benefits**: Better depth estimation improves 3D localization.

---

## Core Concepts

### Depth Ambiguity

**Problem**: Single view cannot determine absolute depth.

**Solutions**:
- Learned depth priors from training data
- Geometric constraints (ground plane, object size)
- Multiple object constraints (relative positioning)

---

### Detection Pipeline

**2D detection**: First detect objects in 2D.

**Depth estimation**: Estimate depth for each object.

**3D box estimation**: Predict 3D bounding box (center, size, rotation).

**Constraints**: Use ground plane, object size priors, geometric consistency.

---

### Geometric Priors

**Ground plane**: Objects rest on ground plane.

**Object size**: Learned average sizes per category.

**Camera calibration**: Known camera parameters.

---

## Applications

- Autonomous driving (monocular cameras)
- Robotics
- AR/VR
- Surveillance

---

## Related Modules

- Module 3.1: Geometry & Camera Models (required for 3D)
- Module 8.1: Multi-View Transformers (easier with multiple views)
- Module 8.2: BEV Models (uses multiple views)

---

## Additional Resources

- **KITTI Dataset**: Common benchmark for monocular 3D detection
- **nuScenes**: Multi-view detection benchmark

---

---
[‚Üê Back to Index](../index.html) | [Next: Occupancy & Scene Completion ‚Üí](08-perception-occupancy.md.html)
---


<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js" charset="utf-8"></script><script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js" charset="utf-8"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
