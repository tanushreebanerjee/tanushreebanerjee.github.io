<!DOCTYPE html>
<meta charset="utf-8" emacsmode="-*- markdown -*-">
<link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/journal.css?">
<style>
/* Burgundy color theme override */
.md h1, .md h2, .md h3, .md h4, .md h5, .md h6 { color: #8B1538; }
.md a { color: #8B1538; }
.md a:hover { color: #A0446C; }

/* System fonts matching personal website */
body, .md { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, sans-serif; }
</style>

<!-- Markdeep: https://casual-effects.com/markdeep/ -->

# 3D Gaussian Splatting

**Module 6.1** | [‚Üê Back to Index](../index.html) | [Next: Dynamic & 4D Gaussians ‚Üí](06-gaussian-dynamic.md.html)

---

## Overview

3D Gaussian Splatting: Real-time neural rendering using 3D Gaussians as primitives. Achieves real-time rendering speeds while maintaining high quality, replacing slower NeRF-based approaches for interactive applications.

---

## Essential Papers

### üî•üî•üî• 3D Gaussian Splatting (2023)

**3D Gaussian Splatting for Real-Time Radiance Field Rendering** (Kerbl et al.) | [arXiv](https://arxiv.org/abs/2308.04079) | [Project](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)

**Key idea**: Represent scene as collection of 3D Gaussians, rasterize them to 2D for real-time rendering.

**3D Gaussian parameterization**:
- Position: $\mu \in \mathbb{R}^3$
- Covariance: $\Sigma = R S S^T R^T$ (rotation $R$ + scaling $S$)
- Opacity: $\alpha$
- Color: Spherical harmonics (SH) coefficients for view-dependent appearance

**Rendering**: Project 3D Gaussians to 2D, rasterize using alpha blending:
$$C = \sum_{i \in N} c_i \alpha_i \prod_{j=1}^{i-1} (1 - \alpha_j)$$

[Figure placeholder: 3D Gaussian splatting pipeline showing Gaussians and rasterization]

**Training**:
1. Initialize from SfM point cloud
2. Adaptive density control (split/clone/prune Gaussians)
3. Differentiable rasterization
4. Optimize with gradient descent (photometric loss)

**Advantages**:
- Real-time rendering (60+ FPS)
- High quality comparable to NeRF
- Fast training (minutes to hours)
- Compact representation

**Limitations**:
- Requires initial point cloud (from COLMAP)
- Large memory for high-resolution scenes
- Artifacts with extreme viewpoints

---

## Core Concepts

### 3D Gaussian Representation

**Gaussian function**: $G(x) = \exp(-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu))$

**Parameterization**:
- Position $\mu$: Center of Gaussian
- Covariance $\Sigma$: Shape/orientation
  - Decomposed as: $\Sigma = R \cdot S \cdot S^T \cdot R^T$
  - Rotation $R$: Quaternion representation
  - Scale $S$: 3D scaling vector

**Opacity** $\alpha$: Controls visibility after sigmoid.

**Color**: Spherical harmonics (SH) for view-dependent appearance:
- Low-order SH captures view-dependent color
- Typically 3 SH bands (16 coefficients)

---

### Differentiable Rasterization

**Projection**: 3D Gaussian ‚Üí 2D Gaussian in image space.

**2D covariance**: $\Sigma' = J \Sigma J^T$ where $J$ is Jacobian of projection.

**Alpha blending**: Front-to-back order, alpha compositing.

**Gradient flow**: Gradient flows through rasterization to Gaussian parameters.

---

### Adaptive Density Control

**Split**: Large Gaussians (high gradient) ‚Üí split into smaller ones.

**Clone**: Small Gaussians with high opacity ‚Üí duplicate in neighboring views.

**Prune**: Remove low-opacity Gaussians.

**Purpose**: Adaptively refine representation during training.

---

## Technical Details

### Training Pipeline

1. **Initialization**: 
   - SfM point cloud from COLMAP
   - Create Gaussians at each point
   - Initialize with small random scales

2. **Differentiable rasterization**:
   - Project Gaussians to image space
   - Rasterize with alpha blending

3. **Loss**:
   - $L = (1-\lambda) L_1 + \lambda L_{D-SSIM}$
   - $L_1$: Pixel-wise L1 loss
   - $L_{D-SSIM}$: Structural similarity loss

4. **Optimization**:
   - SGD with exponential decay
   - Adaptive density control every $N$ iterations

5. **Convergence**: Typically 7,000-30,000 iterations.

---

### Memory and Performance

**Memory**: Scales with number of Gaussians (typically millions).

**Rendering speed**: 60-200+ FPS depending on scene complexity.

**Training time**: Minutes to hours (much faster than NeRF).

**File size**: Typically 50-500 MB per scene.

---

## Problems Solved by Gaussian Splatting

### Real-Time Rendering at NeRF Quality
**Problem**: NeRF achieves high quality but is too slow for real-time applications (seconds per frame). Previous real-time methods sacrificed quality.

**Gaussian Splatting solution**: Achieves real-time rendering (60+ FPS) while maintaining quality comparable to NeRF through efficient rasterization of 3D primitives.

[Figure placeholder: Side-by-side comparison: NeRF rendering (high quality, slow) vs Gaussian Splatting (high quality, real-time)]

### Fast Training
**Problem**: NeRF training takes hours to days, even with acceleration methods.

**Gaussian Splatting solution**: Training completes in minutes to hours, enabling rapid iteration and experimentation.

### Memory Efficiency for Real-Time
**Problem**: Real-time rendering requires storing and efficiently accessing scene representation during inference.

**Gaussian Splatting solution**: Discrete Gaussian primitives enable efficient GPU rasterization and memory access patterns optimized for real-time rendering.

### Interactive Viewing
**Problem**: NeRF requires per-frame rendering computation, making interactive exploration impossible.

**Gaussian Splatting solution**: Real-time performance enables interactive viewing, VR/AR applications, and dynamic camera control.

---

## Remaining Challenges and Limitations

### Initialization Dependency
**Problem**: Requires high-quality point cloud from COLMAP/SfM for initialization. Poor initialization ‚Üí poor results.

**Current solutions**: InstantSplat and other methods try to reduce initialization requirements, but quality still depends on good initial points.

**Open question**: Can we initialize from scratch or very sparse views without SfM?

### Memory for Large Scenes
**Problem**: Large scenes require millions of Gaussians ‚Üí large memory footprint (hundreds of MB to GB).

**Current solutions**: Compression methods, quantization, hierarchical representations.

**Open question**: Can we achieve similar quality with significantly fewer Gaussians?

### Extreme Viewpoints
**Problem**: Rendering from viewpoints far from training views can show artifacts or degraded quality.

**Open question**: Better generalization to novel viewpoints without explicit supervision?

### View-Dependent Effects
**Problem**: While SH coefficients capture view-dependent appearance, very specular surfaces or complex lighting can be challenging.

**Remaining**: Limited by SH representation capacity compared to NeRF's continuous function.

### Dynamic Scenes
**Problem**: Original Gaussian Splatting is static only.

**Current solutions**: 4D Gaussian Splatting (Module 6.2) handles dynamic scenes, but more complex.

**Open question**: Real-time dynamic rendering at same quality and efficiency?

### Geometry Extraction
**Problem**: Gaussians are rendering primitives, not explicit geometry. Extracting meshes requires conversion steps.

**Open question**: Direct mesh generation or better geometry extraction methods?

### Textured/Transparent Surfaces
**Problem**: Thin structures, transparent objects, complex textures can be challenging to represent with discrete Gaussians.

**Remaining**: Some artifacts on fine details, edges.

---

## Broader Insights and Implications

### The Primitive Choice Matters
**Insight**: Gaussian Splatting demonstrates that choosing the right primitive (3D Gaussians) enables dramatically different efficiency/quality trade-offs than implicit representations (NeRF).

**Broader impact**: Opens research direction on primitive selection - different primitives may be optimal for different applications. Hybrid approaches combining primitives show promise.

### Rasterization Still Relevant
**Insight**: While differentiable rendering revolutionized learning, traditional rasterization (when made differentiable) can still be highly efficient for inference.

**Broader impact**: Combines benefits of deep learning (differentiable optimization) with benefits of traditional graphics (efficient rasterization). Shows value of hybrid classical/deep approaches.

### Discrete vs Continuous Representations
**Insight**: Gaussian Splatting uses discrete primitives, NeRF uses continuous function. Each has advantages:
- Discrete: Efficient storage/access, explicit control
- Continuous: Smooth interpolation, compact representation

**Broader impact**: Choice of discrete vs continuous is fundamental design decision. Different problems benefit from different choices.

### Quality vs Speed Trade-off Can Be Shifted
**Insight**: Gaussian Splatting shows that clever representation design can shift the quality/speed Pareto frontier - achieving both better quality AND speed than previous methods in some regimes.

**Broader impact**: Encourages exploration of novel representations. Better representations can improve multiple metrics simultaneously, not just trade-offs.

### The Importance of Initialization
**Insight**: Good initialization (from SfM point cloud) enables fast convergence. Without it, results degrade.

**Broader impact**: Highlights value of multi-stage pipelines (SfM ‚Üí Gaussian Splatting). Classical methods still provide valuable preprocessing for deep learning.

[Placeholder for manual expansion: Add insights about impact on industry, VR/AR applications, real-time graphics, connections to other methods]

---

## Comparison with NeRF

**Gaussian Splatting**:
- Real-time rendering (60+ FPS)
- Fast training (minutes to hours)
- Requires point cloud initialization
- Discrete primitives
- Memory: 50-500 MB per scene

**NeRF**:
- Slow rendering (seconds per frame)
- Slow training (hours to days)
- Continuous representation
- Better extrapolation to novel views
- Memory: 5-10 MB per scene (more compact)

**Use cases**:
- Gaussian Splatting: Real-time applications, VR/AR, interactive viewing, gaming
- NeRF: Highest quality offline rendering, research, when real-time not needed

[Figure placeholder: Comparison table showing detailed metrics: rendering speed, training time, quality metrics, memory usage, initialization requirements]

---

## Extensions

- **4D Gaussian Splatting**: Dynamic scenes (Module 6.2)
- **Animatable Gaussians**: Deformable objects
- **Gaussian avatars**: Human rendering
- **Scene-level Gaussians**: Large-scale scenes
- **InstantSplat**: Faster initialization/training

---

## Related Modules

- Module 3.2: Structure-from-Motion (provides initialization)
- Module 5.1: NeRF Fundamentals (alternative approach)
- Module 6.2: Dynamic & 4D Gaussians
- Module 7.1: Score Distillation (generative Gaussian methods)

---

## Additional Resources

- **Official Repository**: [repo-sam.inria.fr](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)
- **Gaussian Splatting Viewer**: Interactive viewing tools
- **Extensions**: Community implementations and variants

---

<div style="text-align: center; margin-top: 2em;">
[‚Üê Back to Index](../index.html) | [Next: Dynamic & 4D Gaussians ‚Üí](06-gaussian-dynamic.md.html)
</div>

<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js" charset="utf-8"></script><script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js" charset="utf-8"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
