<!DOCTYPE html>
<meta charset="utf-8" emacsmode="-*- markdown -*-">
<link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/journal.css?">
<style>
/* Burgundy color theme override */
.md h1, .md h2, .md h3, .md h4, .md h5, .md h6 { color: #8B1538; }
.md a { color: #8B1538; }
.md a:hover { color: #A0446C; }
</style>

<!-- Markdeep: https://casual-effects.com/markdeep/ -->

# SLAM

**Module 3.4** | [‚Üê Back to Index](../index.html) | [Next: Optical Flow ‚Üí](../index.html)

---

## Overview

Simultaneous Localization and Mapping (SLAM): Estimate camera trajectory and map environment simultaneously in real-time. Essential for robotics and augmented reality.

---

## Essential Papers

### üìñ ORB-SLAM (2015)

**ORB-SLAM: A Versatile and Accurate Monocular SLAM System** (Mur-Artal et al.) | [arXiv](https://arxiv.org/abs/1502.00956)

**Key features**:
- Feature-based tracking (ORB features)
- Keyframe-based mapping
- Loop closure detection
- Relocalization

**Pipeline**:
1. **Tracking**: Match features, estimate camera pose
2. **Mapping**: Add keyframes, triangulate new map points
3. **Loop closing**: Detect revisited locations, optimize map

**Modules**:
- **Tracking thread**: Real-time pose estimation
- **Local mapping**: Add keyframes and points
- **Loop closing**: Global optimization

---

### DSO (2016)

**Direct Sparse Odometry** (Engel et al.) | [arXiv](https://arxiv.org/abs/1607.02565)

**Key idea**: Direct method (optimize photometric error) instead of features.

**Advantages**: Works in low-texture regions, more accurate.

**Disadvantages**: Sensitive to photometric calibration, slower.

---

### üî• NICE-SLAM (2022)

**Neural Implicit SLAM** (Zhu et al.) | [arXiv](https://arxiv.org/abs/2112.12130)

**Key innovation**: Neural implicit representation for mapping.

**Representation**: Hierarchical feature grid (like instant-NGP) for scene.

**Advantages**: 
- Dense geometry and appearance
- Real-time optimization
- Photo-realistic rendering

**Applications**: Dense SLAM for AR/VR.

---

### üî• DROID-SLAM (2021)

**DROID-SLAM: Deep Visual SLAM** (Teed & Deng) | [arXiv](https://arxiv.org/abs/2108.10869)

**Key innovation**: Dense optical flow + bundle adjustment.

**Pipeline**:
1. Dense correspondence via optical flow (RAFT)
2. Bundle adjustment with learned update operator
3. Dense depth map estimation

**Advantages**: Dense tracking, robust, accurate.

**Supports**: Monocular, stereo, RGB-D cameras.

---

### üöÄ Gaussian-SLAM (2024)

**Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting**

**Key innovation**: 3D Gaussian Splatting for SLAM representation.

**Benefits**: Real-time rendering, photo-realistic maps, efficient.

---

## Core Concepts

### Feature-Based SLAM

**Process**:
1. Extract features (ORB, SIFT)
2. Match features across frames
3. Estimate pose (PnP)
4. Triangulate landmarks
5. Bundle adjustment

**Advantages**: Robust, well-established.

**Limitations**: Requires texture, sparse maps.

---

### Direct SLAM

**Process**: Optimize photometric error directly.

**Advantages**: Dense tracking, works in low-texture regions.

**Limitations**: Sensitive to lighting changes, calibration.

---

### Neural Implicit SLAM

**Representation**: Neural network encodes scene geometry/appearance.

**Advantages**: Dense maps, rendering capabilities.

**Challenges**: Real-time optimization, scalability.

---

## SLAM Pipeline

**Frontend** (Tracking):
- Feature extraction/matching
- Pose estimation
- Frame selection (keyframes)

**Backend** (Mapping):
- Landmark triangulation
- Bundle adjustment
- Loop closure detection

**Map representation**:
- **Feature-based**: Sparse point cloud
- **Direct**: Dense depth maps
- **Neural**: Implicit representation

---

## Problems Solved by SLAM

### Real-Time Localization and Mapping
**Problem**: Need to know where you are (localization) and what environment looks like (mapping) in real-time, without prior map.

**SLAM solution**: Simultaneously estimate camera trajectory and build map. Essential for robotics, AR/VR.

[Figure placeholder: SLAM visualization showing camera trajectory being estimated and map being built simultaneously]

### Handling Unknown Environments
**Problem**: Operating in unknown environments requires building map on-the-fly while localizing.

**Solution**: SLAM builds map while localizing. No prior map needed.

---

## Remaining Challenges and Limitations

### Scale and Long-Term Operation
**Problem**: Large-scale environments, long-term operation can cause drift, map inconsistencies.

**Open question**: Better large-scale SLAM? Long-term consistency?

### Dynamic Environments
**Problem**: Moving objects violate static world assumption. Can corrupt map and localization.

**Open question**: Better handling of dynamic scenes?

### Real-Time Constraints
**Problem**: Must operate in real-time. Balancing accuracy and speed challenging.

**Open question**: Better efficiency? More accurate real-time methods?

---

## Broader Insights and Implications

### Real-Time vs Offline
**Insight**: SLAM shows difference between real-time (SLAM) and offline (SfM) reconstruction. Different constraints, different methods.

**Broader impact**: Highlights importance of real-time constraints. Influences design of real-time systems.

### Neural vs Classical
**Insight**: Neural SLAM (NICE-SLAM, Gaussian-SLAM) shows neural methods can improve classical SLAM. Hybrid approaches valuable.

**Broader impact**: Demonstrates value of combining classical geometry with neural methods.

[Placeholder for manual expansion: Add insights about applications, connections to other methods]

---

## Related Modules

- Module 3.1: Geometry & Camera Models (epipolar geometry, PnP)
- Module 3.2: Structure-from-Motion (offline reconstruction)
- Module 4.1: Optical Flow (dense tracking)
- Module 6.1: Gaussian Splatting (Gaussian-SLAM)

---

## Additional Resources

- **ORB-SLAM**: [github.com/raulmur/ORB_SLAM3](https://github.com/raulmur/ORB_SLAM3)
- **NICE-SLAM**: Repository and code

---

<div style="text-align: center; margin-top: 2em;">
[‚Üê Back to Index](../index.html) | [Previous: Multi-View Stereo ‚Üê](03-3d-mvs.md.html)
</div>

<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js" charset="utf-8"></script><script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js" charset="utf-8"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
