<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Datasets</title>
<script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js"></script>
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
</head>
<body>

<code style="display:none">
<!-- Markdeep: https://casual-effects.com/markdeep/ -->

# Datasets

**Module 12.2** | [← Back to Index](../index.md.html) | [Previous: Libraries & Tools ←](12-tools-libraries.md.html)

---

## Overview

Key datasets for 3D/4D computer vision, neural rendering, and spatial understanding. From autonomous driving to indoor scenes.

---

## Autonomous Driving

### nuScenes
**Website**: [nuscenes.org](https://www.nuscenes.org/)

**Purpose**: Multi-modal autonomous driving dataset.

**Features**:
- 6 cameras (360° coverage)
- LiDAR
- Radar
- 3D bounding boxes
- Maps

**Use cases**: BEV detection, multi-view perception, tracking

---

### Waymo Open Dataset
**Website**: [waymo.com/open](https://waymo.com/open)

**Purpose**: Large-scale autonomous driving dataset.

**Features**:
- 5 cameras
- LiDAR
- High resolution
- Dense annotations

**Use cases**: 3D detection, BEV models, perception

---

### KITTI
**Website**: [www.cvlibs.net/datasets/kitti](http://www.cvlibs.net/datasets/kitti)

**Purpose**: Classic autonomous driving benchmark.

**Features**:
- Stereo cameras
- LiDAR
- 2D/3D object detection
- Tracking

**Use cases**: Monocular 3D detection, tracking

---

## Indoor Scenes

### ScanNet
**Website**: [scannet.princeton.edu](http://scannet.princeton.edu/)

**Purpose**: Large-scale indoor scene dataset.

**Features**:
- RGB-D videos
- 3D meshes
- Semantic labels
- Camera poses

**Use cases**: Scene understanding, 3D reconstruction, SLAM

---

### 3D-FRONT / 3D-FUTURE
**Purpose**: Synthetic indoor scenes.

**Features**: High-quality 3D scenes, furniture models

**Use cases**: Scene generation, 3D understanding

---

## Neural Rendering

### NeRF Datasets
**Common datasets**:
- **LLFF**: Real forward-facing scenes
- **Synthetic NeRF**: Synthetic 360° scenes
- **MipNeRF-360**: 360° unbounded scenes
- **Tanks and Temples**: Large scenes

**Features**: Multi-view images, camera poses, often generated with COLMAP

---

### Dynamic NeRF Datasets
- **HyperNeRF**: Dynamic scenes
- **D-NeRF**: Synthetic dynamic scenes

---

## Human Datasets

### Human3.6M
**Purpose**: 3D human pose dataset.

**Features**: MoCap data, multiple views, actions

---

### 3DPW
**Purpose**: 3D Pose in the Wild.

**Features**: Outdoor scenes, SMPL fits

---

### THUMOS
**Purpose**: Human action recognition.

---

## Optical Flow & Matching

### Sintel
**Purpose**: Optical flow benchmark.

**Features**: Synthetic scenes, ground truth flow

---

### KITTI (see above)
Also includes optical flow ground truth.

---

### FlyingThings3D
**Purpose**: Scene flow dataset.

**Features**: Synthetic scenes, 3D motion

---

## Related Modules

- Module 3.2: Structure-from-Motion (COLMAP data processing)
- Module 5.1: NeRF Fundamentals (NeRF datasets)
- Module 8.2: BEV Models (nuScenes, Waymo)

---

## Additional Resources

- **Papers with Code Datasets**: [paperswithcode.com/datasets](https://paperswithcode.com/datasets)
- Individual dataset websites for download and documentation

---

<div style="text-align: center; margin-top: 2em;">
[← Back to Index](../index.md.html) | [Previous: Libraries & Tools ←](12-tools-libraries.md.html)
</div>

</code>
</body>
</html>
